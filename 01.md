[TOC]

<div STYLE="page-break-after: always;"></div>

# 上课

神人助教，九点零二才说，不是十点上课，而是九点开始上课

模电实验小组分崩离析，另起炉灶

---

机器学习（ML）：inductive rather than deductive

deductive：演绎，比如用几何公理严谨的推出一大坨定理

前面在讲一大坨 ML 的概念，举例之类的

ML Tasks

1. Supervised Learning（在有标注训练集上训练）
2. Unsupervised Learning（在无标注训练集上训练）
3. Reinforcement

**ML Components**

比如比较两个人谁更好，这是一个复杂的问题

- Representation
  - **提取**出两个人的**特征**，使得其能够被比较
- Evaluation
  - 从特征弄出一个**值**（或者一个向量）
- Optimisation
  - 根据我们的假设（我们的预期）来改进模型，Motivating

**需要的数学技巧**

**e.g. 制造咖啡厅偶遇**

x: 离开教室的时间

y: 到达咖啡厅的时间

如果有两个点，我们会选择用线性拟合

Representation

- 离开咖啡厅的时间
  - 路程一定，假设速度一定？（线性模型）
  - 如果出发的晚了，会不会走的急一点?（非线性模型）
  - 如果遇上了认识的同学，又会怎么样?（随机事件）
  - ...

严谨的表达一下：

- Inputs
  - $x=[1,x_1,\cdots,x_m]^T$
- Outputs
  - $y\in\R$
- Training Data
  - $S=\{(x^{(i)},y^{(i)})\}$

- 线性回归模型

不知道，听不懂了，总结一下需要的四个数学基础：

- 线性代数

- 微积分

- 概率论

- 统计学


---

# 下午自己鼓捣的内容

安装 Anaconda，配置各种环境

基本按照 Installation Guide 里的来，注意自己添加一下 Conda 的环境变量

**创建虚拟环境**

```bash
conda create --name <your_name> python=3.7.3 numpy pandas scipy scikit-learn tensorflow keras matplotlib seaborn

conda install notebook ipykernel
```

jyc 取名为 `xjtu-ml`，下文就统一用它了 rua

**激活虚拟环境**

```bash
conda activate xjtu-ml
```

发现会报错，需要先执行

```bash
conda init
```

出现提示

```text
==> For changes to take effect, close and re-open your current shell. <==
```

所以就关闭终端，然后再重新输入 `activate` 那个命令

发现 JB 的还是报错，在 StackOverflow 上搜索了一下，发现解决步骤如下：

```bash
source activate xjtu-ml
conda activate xjtu-ml
```

然后就可以啦啦啦啦

**一些 conda 命令**

```bash
conda env list   # 查看已创建环境
conda list       # 显示安装过的包
```

**把 conda 环境导入到 pycharm 中**

<img src=".\img\image-20250630153859726.png" alt="image-20250630153859726" style="zoom:80%;" />

<img src=".\img\image-20250630153811528.png" alt="image-20250630153811528" style="zoom:67%;" />

```text
添加新的解释器->添加本地解释器->选择现有
```

**类型** 选择 Conda，前面配置好 Conda 的环境变量的话，会自动识别好 conda  的路径

选择刚刚创建的环境即可

---

# 作业

如何加载作业？用 pycharm 打开作业（.ipynb）所在的文件夹即可

## 1 设置目录加载数据

简单，rua

```python
dirName = r"D:\A_devcpp\2023SummerVacationStart2Write\Machine Learning\Notebook 1 End to End Project" #TO_DO input the path of the folder for the data files below
```

- `r"string"` 代表这是原始字符串，能够避免 Windows 中 `\` 被转义

```python
dirName_feats = os.path.join(dirName,'housing_features.csv')
dirName_targs = os.path.join(dirName,'housing_target.csv')
dirName_names = os.path.join(dirName,'housing_names.csv')
```

- 用 `os.path.join()` 能够构建文件的完整路径

```python
df_housing = pd.read_csv(dirName_feats)
```

- 将特征数据读入Pandas DataFrame

```python
df_housing.describe()
```

- 生成数据集的统计摘要：
  - 每列的数量(count)
  - 均值(mean)
  - 标准差(std)
  - 最小值(min)
  - 四分位数(25%,50%,75%)
  - 最大值(max)

```python
df_housing.head()
```

- 显示DataFrame的前5行数据
- 对于这个例子而言，其实就是显示 `housing_features.csv` 这个文件的前五行

```python
X=np.genfromtxt(dirName_feats,delimiter=',',skip_header=1)
y=np.genfromtxt(dirName_targs,delimiter=',',skip_header=1)
names=np.genfromtxt(dirName_names, dtype='str',skip_header=1)
```

- 将数据加载为NumPy数组
- 参数说明：
  - `delimiter=','`: CSV文件的分隔符
  - `dtype='str'`: 指定读取为字符串类型
  - `skip_header=1`: 跳过第一行（标题行）
- 结果
  - `X`是形状为`(n_samples, n_features)`的二维数组，`X[i][j]` 即是第 $i$ 个样本的第 $j$ 个特征
  - `y`是形状为`(n_samples,)`的一维数组
  - `names`是包含特征名称的一维字符串数组

## 2 数据集预处理

### 2.1 填补缺失数据

```python
np.random.seed(42)

X_new = X.copy()
mask = np.random.randint(0, 2, size=X.shape).astype(bool)
X_new[mask] = np.nan
```

- 设置随机种子为 42，采用固定值是为了使结果能得到复现，并能保持随机过程的一致性
- `.copy()` 是深拷贝，不会共享内存
- `np.random.randint(0, 2, size=X.shape)`：生成与`X`形状相同的随机整数矩阵，值域[0,2)即取值0或1
- `.astype(bool)`：将0/1转换为布尔值（0→`False`, 1→`True`）
- 所以 `mask` 矩阵和 `X` 形状一致，但是是 bool 矩阵
- `X_new[mask] = np.nan`，将 `mask` 中 `True` 位置对应的元素设置为 NaN

```python
imp = SimpleImputer(strategy='mean')
X_replace_with_mean = imp.fit_transform(X_new)
```

- `SimpleImputer`：Scikit-Learn 的缺失值填充工具

- `strategy='mean'`：指定填充策略为**均值填充**
  - 其他常用策略：`median`（中位数）, `most_frequent`（众数）, `constant`（固定值）
- `fit_transform` 相当于先 `fit()` 再 `transform()`
  - `fit()` 就是计算每一个特征的填充值（用 `mean` 就是取平均值）
  - `transform()` 就是用该特征值列计算出的填充值，填充该列的 NaN


```python
########################################################
# TO_DO
#[your code here]
imp = SimpleImputer(strategy='median')
X_replace_with_median = imp.fit_transform(X_new)
imp = SimpleImputer(strategy='most_frequent')
X_replace_with_most_frequent = imp.fit_transform(X_new)
# /TO_DO
########################################################
```

### 2.2 划分训练集和测试集

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

```text
原始数据集 (100%)
├── 训练集 (80%) → 用于模型训练
│   ├── X_train: 特征矩阵的子集
│   └── y_train: 对应标签的子集
└── 测试集 (20%) → 用于模型评估
    ├── X_test: 特征矩阵的子集
    └── y_test: 对应标签的子集
```

$X$ 是特征矩阵集合（Representation 集合），$y$ 是对应的标签集合 (Value 集合)

### 2.3 数据集标准化

就是经典的
$$
x_{std}=\dfrac{x-\mu}{\sigma}
$$
$\mu$ 是均值，$\sigma$ 是标准差

```python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

- 第二行就是，对每个特征列，计算出对应的 $\mu, \sigma$，并相应的进行标准化处理
- 第三行使，对每个特征列，用第二行计算出的 $\mu,\sigma$ 来进行标准化（用训练集的数据来标准化），以避免数据泄露

## 3 回归分析

### 3.1 基准模型

```python
# 基准预测，创建一个全一的数组，然后乘上训练集的平均值
y_avg = np.ones(len(y_test)) * np.mean(y_train)

mse_avg = mean_squared_error(y_test, y_avg)    # 计算均方误差
mae_avg = mean_absolute_error(y_test, y_avg)   # 计算绝对误差
```

**均方误差 MSE**：$\dfrac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2$

**平均绝对误差 MAE**：$\dfrac{1}{n}\sum_{i=1}^{n}\vert y_i-\hat{y}_i\vert$

其中 $n$ 是测试集样本总数，$y_i$ 是真实值，$\hat{y}_i$ 是模型给出的值

### 3.2 线性回归

```python
lr = LinearRegression()          # 创建线性回归模型对象
lr.fit(X_train, y_train)         # 使用训练数据拟合模型

y_lr = lr.predict(X_test)        # 对测试集进行预测

mse_lr = mean_squared_error(y_test, y_lr)   # 计算均方误差
mae_lr = mean_absolute_error(y_test, y_lr)  # 计算平均绝对误差
```

```python
n_sample, n_feature = X_train.shape

mse_lr_per_feature = []
mae_lr_per_feature = []

########################################################
# TO_DO
#[your code here]

for counter in range(X_train.shape[1]):  # 遍历每个特征
    lr = LinearRegression()
    # 重塑数据为二维数组 (sklearn要求)
    X_train_feat = np.reshape(X_train[:, counter], [X_train.shape[0], 1])
    # 使用单个特征训练
    lr.fit(X_train_feat, y_train)

    # 准备测试数据
    X_test_feat = np.reshape(X_test[:, counter], [X_test.shape[0], 1])
    y_lr = lr.predict(X_test_feat)

    # 计算并存储误差 (MSE取平方根->RMSE)
    mse_lr_per_feature.append(np.sqrt(mean_squared_error(y_test, y_lr)))
    mae_lr_per_feature.append(mean_absolute_error(y_test, y_lr))

# 创建结果DataFrame
errors = pd.DataFrame.from_dict(
    {'MAE': mae_lr_per_feature, 'MSE': mse_lr_per_feature},
    orient='index',
    columns=names  # 使用特征名称作为列名
)

# /TO_DO
########################################################

errors
```

`np.reshape` ：

- 对于二维数组 `a`，`a[:, i]` 会返回 `a` 中第 `i` 列所有元素构成的一维数组

- `np.reshape(..., [n, 1])`：将一维数组转为二维 (n行1列)
- **为什么需要**：sklearn 要求特征矩阵是二维，即使单特征也需要`(n_samples, 1)`形状

`pd.DataFrame.from_dict()` ：

- `pd.DataFrame.from_dict()`：从字典创建 DataFrame
- `orient='index'`：字典键作为行索引
- `columns=names`：使用特征名称作为列名

### 3.3 K近邻回归 KNN

```python
n_neighbors = 2  # 设置近邻数量
neigh = KNeighborsRegressor(n_neighbors=n_neighbors)  # 创建K近邻回归模型
neigh.fit(X_train, y_train)  # 使用训练数据拟合模型

y_neigh = neigh.predict(X_test)  # 对测试集进行预测

mse_neigh = np.sqrt(mean_squared_error(y_test, y_neigh))  # 计算RMSE
mae_neigh = mean_absolute_error(y_test, y_neigh)  # 计算MAE
print('MSE Neigh 4: {}'.format(mse_neigh))  # 打印结果
print('MAE Neigh 4: {}'.format(mae_neigh))
```

```python
mse_neigh_other_num = []
mae_neigh_other_num = []

########################################################
# TO_DO
#[your code here]

for n_neighbors in range(4, 7):
    neigh = KNeighborsRegressor(n_neighbors=n_neighbors)
    neigh.fit(X_train, y_train)
    
    y_neigh = neigh.predict(X_test)
    
    mse_neigh_other_num.append(mean_squared_error(y_test, y_neigh))
    mae_neigh_other_num.append(mean_absolute_error(y_test, y_neigh))


errors = pd.DataFrame.from_dict({'MAE': mae_neigh_other_num,
                                 'MSE': mse_neigh_other_num},
                                 orient='index', columns=range(4, 7))

# /TO_DO
########################################################

errors
```

这个感觉，看一遍代码就看懂了 rua

注意 `range(l,r)` 返回 `[l,r-1]` 的整数序列，不包含 `r`

### 3.4 梯度提升回归

```python
gb = GradientBoostingRegressor(loss='squared_error', alpha=0.75,
                               n_estimators=250, max_depth=3,
                               learning_rate=.1, min_samples_leaf=9,
                               min_samples_split=9)
gb.fit(X_train, y_train)

y_gb = gb.predict(X_test)

mse_gb = mean_squared_error(y_test, y_gb)
mae_gb = mean_absolute_error(y_test, y_gb)
```

```python
losses = ['squared_error', 'quantile']
alphas = np.linspace(0.7, 0.9, 5)

mse_gb_other_param = np.empty([len(losses), len(alphas)])
mae_gb_other_param = np.empty([len(losses), len(alphas)])

########################################################
# TO_DO
#[your code here]

for loss_counter, loss in enumerate(losses):
    for alpha_counter, alpha in enumerate(alphas):
        gb = GradientBoostingRegressor(loss=loss, alpha=alpha,
                                        n_estimators=250, max_depth=3,
                                        learning_rate=.1, min_samples_leaf=9,
                                        min_samples_split=9)
        gb.fit(X_train, y_train)
        y_gb = gb.predict(X_test)
        
        mse_gb_other_param[loss_counter, alpha_counter] = mean_squared_error(y_test, y_gb)
        mae_gb_other_param[loss_counter, alpha_counter] = mean_absolute_error(y_test, y_gb)
        
mse_errors = pd.DataFrame(data=mse_gb_other_param,index=losses, columns=alphas)        
mae_errors = pd.DataFrame(data=mae_gb_other_param,index=losses, columns=alphas)        

# /TO_DO
########################################################
```

首先是 `gb` 的一些参数的解释

```python
GradientBoostingRegressor(
    loss='squared_error',   # 损失函数：均方误差
    alpha=0.75,             # 分位数损失的分位数（仅用于'quantile'损失）
    n_estimators=250,       # 弱学习器（树）的数量
    max_depth=3,            # 每棵树的最大深度
    learning_rate=.1,       # 学习率（收缩因子）
    min_samples_leaf=9,     # 叶节点所需最小样本数
    min_samples_split=9     # 内部节点分裂所需最小样本数
)
```

然后是两个语法

`np.linspace(0.7, 0.9, 5)`

- 从 `[0.7, 0.9]` 均匀生成 5 个元素

`for counter, val in enumerate(array):`

- `enumerate(array)` 会生成一个包含索引和值的元组序列
- `counter` 是当前的索引
- `val` 是对应的值

### 3.5 不同模型比较

```python
fig, axes = plt.subplots(2, 2, sharex=True)

mse = [mse_avg, mse_lr, mse_neigh, mse_gb]
mae = [mae_avg, mae_lr, mae_neigh, mae_gb]

titles = ['average y', 'linear regression', 'KNN', 'gradient boosting']
predictions = [y_avg, y_lr, y_neigh, y_gb]

for counter, ax in enumerate(axes.flat):
    ax.scatter(predictions[counter], y_test)
    ax.set_title(titles[counter])

plt.show()
```

```python
errors = pd.DataFrame.from_dict({'MAE': [mae_avg, mae_lr, mae_neigh, mae_gb],
                                 'MSE': [mse_avg, mse_lr, mse_neigh, mse_gb]},
                                orient='index', columns=titles)
errors
```

第二部分代码就是创建一个表格，这个在前面已经讲过啦

第一部分是画图

```python
fig, axes = plt.subplots(2, 2, sharex=True)
```

- `plt.subplots(2, 2)`：创建2行2列的子图网格
- `sharex=True`：所有子图共享x轴（统一刻度）
- 返回值：
  - `fig`：整个图形对象
  - `axes`：2x2数组，包含4个子图对象（按行优先顺序）

```python
mse = [mse_avg, mse_lr, mse_neigh, mse_gb]
mae = [mae_avg, mae_lr, mae_neigh, mae_gb]
titles = ['average y', 'linear regression', 'KNN', 'gradient boosting']
predictions = [y_avg, y_lr, y_neigh, y_gb]
```

- 创建4个模型的指标和预测结果列表：
  - `mse`：均方误差列表
  - `mae`：平均绝对误差列表
  - `titles`：模型名称列表
  - `predictions`：测试集预测值列表

```python
for counter, ax in enumerate(axes.flat):
    ax.scatter(predictions[counter], y_test)
    ax.set_title(titles[counter])
```

- `axes.flat`：将2x2子图数组展平为一维迭代器
- `enumerate()`：同时获取计数器(counter)和子图对象(ax)
- 每个子图绘制：
  - `ax.scatter()`：预测值(x轴) vs 真实值(y轴)的散点图
  - `ax.set_title()`：设置子图标题为模型名称
- 循环处理4个子图

```python
plt.show()
```

- 显示图形

最后的问题不想想了，直接上 DeepSeek 吧

> **影响分析**：
>
> - KNN中较小的K值（如K=2）易受噪声影响，较大的K值（K=5-6）更稳定
> - GBR中`loss='quantile'`配合高alpha（0.9）对异常值更鲁棒
